{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "571f9797-9f00-4d6f-821f-14d98337dfd6",
   "metadata": {},
   "source": [
    "# Keyword Extraction using Machine Learning\n",
    "I have the task of Natural language processing that automatically identifies a set of terms to describe the subject of the text. This is an important method in information retrieval (IR) systems: keywords simplify and speed up research. Keyword extraction can be used to reduce text dimensionality for further text analysis (subject modeling text classification).\n",
    "The task of keyword extraction can be used in automatically indexing data, summarizing text, or generating tag clouds with the most representative keywords.\n",
    "\n",
    "Here is my Machine Learning project on Keyword Extraction with Python programming language. \n",
    "\n",
    "### Step 1: Import Necessary Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e8492d-ea8f-4a6b-ad60-a26868951df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5213ff9e-f40f-472c-a34c-bd5bfb425779",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/papers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e4e461-83c7-488d-b21d-ce9bab2d220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e92277-fcec-4fb5-a5fb-22cb3bf914e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf72983-b44e-4314-a9cb-5eb237d46612",
   "metadata": {},
   "source": [
    "#### Observations: I see that the dataset contains the id, year, title and more. However, the columns such as event type and abstract seem to be missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f70e50c-da60-43d0-8ba8-c61e18fba081",
   "metadata": {},
   "source": [
    "### Step 2: Preprocess textual data\n",
    "I will use NLTK library in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a6620e-c22d-4ba1-90fb-555e7b7907f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87753fa-94ce-41b2-802f-2403ae733e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35728337-05e1-4549-8ed1-fbbc3412b543",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eccc86-1cf7-4ad4-b02c-968d6ea92f1a",
   "metadata": {},
   "source": [
    "#### Create a lost of custom stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f38d1e-1c30-44ab-b9a0-fd115091ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "##Creating a list of custom stopwords\n",
    "new_words = [\"fig\",\"figure\",\"image\",\"sample\",\"using\", \n",
    "             \"show\", \"result\", \"large\", \n",
    "             \"also\", \"one\", \"two\", \"three\", \n",
    "             \"four\", \"five\", \"seven\",\"eight\",\"nine\"]\n",
    "stop_words = list(stop_words.union(new_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c209d85e-92cb-476a-9763-0671a015f5e8",
   "metadata": {},
   "source": [
    "#### Created a preprocessing function used in a keyword extraction project, designed to clean and normalize text data before analyzing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321e53e-f460-48f3-8a59-272669bcb692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(text):\n",
    "    #Lowercase Conversion \n",
    "    #converts all characters in the input text to lowercase. \n",
    "    text = text.lower()\n",
    "    \n",
    "    #Remove HTML Tags\n",
    "    text = re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "    \n",
    "    #Remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    #Convert to list from string\n",
    "    text = text.split()\n",
    "    \n",
    "    # remove stopwords\n",
    "    #Explanation: Stopwords are common words like \"the\", \"is\", \"in\", \n",
    "    #which are generally considered irrelevant for keyword extraction \n",
    "    #because they do not contribute significantly to the text's main topics.\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    \n",
    "    # remove words less than three letters\n",
    "    text = [word for word in text if len(word) >= 3]\n",
    "    \n",
    "    #Lemmatize\n",
    "    #Clarification: Lemmatization is the process of reducing words to their base or dictionary form (lemma). \n",
    "    # A WordNetLemmatizer is used here to lemmatize each word in the list. \n",
    "    # This step is important for keyword extraction because it helps in recognizing different forms of the \n",
    "    # same word as a single keyword (e.g., \"runs\", \"running\", and \"ran\" would all be converted to \"run\")\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    text = [lmtzr.lemmatize(word) for word in text]\n",
    "    \n",
    "    return ' '.join(text)\n",
    "docs = df['paper_text'].apply(lambda x:pre_process(x))\n",
    "docs = docs.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b0c10e-bfa6-41e6-a4e5-73facd6fc2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vocabulary of words,\n",
    "cv = CountVectorizer(max_df=0.95,\n",
    "                     #ignore words that appear in 95% of documents\n",
    "                     max_features = 10000, # the size of the vocabulary\n",
    "                     ngram_range = (1,3)\n",
    "                    )\n",
    "word_count_vector = cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe409d-3d35-4d78-ba28-7b3353c5864c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9c1704-daea-4a0c-a4da-c3a1b1d25b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = \"abcd\"\n",
    "word2 = \"pq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331bf9c3-517e-4ee2-ad9c-0ab1b493af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeAlternately(word1: str, word2: str):\n",
    "    if len(word1) == 0:\n",
    "        return word2\n",
    "    \n",
    "    elif len(word2) == 0:\n",
    "        return word1\n",
    "    \n",
    "    elif len(word1) == len(word2):\n",
    "        merged = []\n",
    "        for i in range(len(word1)):\n",
    "            merged.append(word1[i])\n",
    "            merged.append(word2[i])\n",
    "    elif len(word1) < len(word2):\n",
    "        merged = []\n",
    "        for i in range(len(word1)):\n",
    "            merged.append(word1[i])\n",
    "            merged.append(word2[i])\n",
    "        merged.append(word2[len(word1):len(word2)])\n",
    "    else:\n",
    "        merged = []\n",
    "        for i in range(len(word2)):\n",
    "            merged.append(word1[i])\n",
    "            merged.append(word2[i])\n",
    "        merged.append(word1[len(word2):len(word1)])\n",
    "    print(merged)\n",
    "    print(''.join(merged))\n",
    "    print(type(merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00cc4a9-07a2-42b8-b0c4-7f5b98bd7b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeAlternately(word1, word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e685e2ec-62c1-419b-950f-0f7b8b938302",
   "metadata": {},
   "outputs": [],
   "source": [
    "str4 = str2*2\n",
    "str4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871cd9e9-5c37-49c9-ac7e-394a46ea7003",
   "metadata": {},
   "outputs": [],
   "source": [
    "str3 = str2+str2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bfb785-1a7a-46a7-be52-00461d45f5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "str3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99501a25-3f3b-4101-ba25-8538483bdd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6, 0,-2):\n",
    "    print(i, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e13c39e-0f38-4c9a-a99d-9ea8edd79c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65767607-2acb-410c-8528-aadb62d51e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'AAAAAAAAAA'\n",
    "b = 'AAAAA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192eec6f-115f-4f5f-9859-d20e49c150d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e38d3a1-29b0-4cf3-8d44-2fe37372bd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000a15a3-4a41-4b1c-85bf-39064f53414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5048bd-ce84-4af2-91b6-f9b2e3c8c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e75be4-52e5-4bb1-9c8f-98fdc3c9ff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0]*len(a) == a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8460e591-f05e-4590-a60b-a4cb1300fc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[:4]*(len(b)//4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e025b12-d198-42d4-80f6-b5d1ba81c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f134ad74-a375-4917-a2d4-894aa8355ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[4:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d0d9fe-a2cb-4fe8-852c-12ed581cbfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dae708-008e-48f0-a613-2cbc10261a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaf4899-47cb-4c21-bf13-84855257d18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(str1)%len(str2) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63cc1b7-27a6-4cf5-b554-1aa29bcf9710",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(str2)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0bc352-c0b2-4907-919a-08f790b67b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(str1)%len(str2) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38114c74-b118-4741-8d4a-bfe9fc15ff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls =[]\n",
    "if len(str2) < len(str1):\n",
    "    if str1 == str2+str2:\n",
    "        ls = str2\n",
    "    elif 1 == 1:\n",
    "        #first loop i = 6\n",
    "        for i in range(len(str2),0,-2):\n",
    "            if str2[:i]*(len(str2)//i) == str2:\n",
    "                ls = str2[:i]\n",
    "            else:\n",
    "                continue\n",
    "    elif (str2[0]*len(str2) == str2) & (str2[0]*len(str1) == str1):\n",
    "        ls = str1[0]\n",
    "    else:\n",
    "        ls=[]\n",
    "print(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bbcbfa-af0c-4b63-855b-d3c457192d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "b = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34240347-5b3e-4ac2-9646-84cee6460b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = b\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23548179-2d21-43c0-b679-f377643e1d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8808ff67-8e56-4ce2-9b92-993d9e30ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = c\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aa914f-2b5f-4929-8f9e-5835c9d916b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = str2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cfc0ab-a25d-4ca4-bb3c-e85e890cb7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92914642-c182-4479-a692-b781fa41d67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "str3 = str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b0b4f6-a248-40d0-9aed-41843bff1727",
   "metadata": {},
   "outputs": [],
   "source": [
    "str2 = str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3487b8-cdda-432a-a691-ddbc49a31fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5537dc-939b-442d-a411-6536d6192418",
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 == str2+str2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd7df74-6f89-4df9-8041-3f4df0eb493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"NLZGMNLZGMNLZGMNLZGMNLZGMNLZGMNLZGMNLZGM\"\n",
    "str2 = \"NLZGMNLZGMNLZGMNLZGMNLZGMNLZGMNLZGMNLZGMNLZGM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154f9cfa-eb95-4147-9167-94012ee1e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a1ca0-f484-40c0-ab73-4296ba6eb625",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(str1),0,-1):\n",
    "    if str2[:i]*(len(str2)//i) == str2:\n",
    "        print(i)\n",
    "        if str2[:i]*(len(str1)//i) == str1:\n",
    "            print(i)\n",
    "            ls = str2[:i]\n",
    "            print(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc72301-5a91-4990-9759-828c8f3eb27a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b804616-7b0c-4501-a6ed-e744144948b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "str2[:3]*(len(str2)//3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194acdc6-c4ea-4fa8-86a8-961710e4d08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls =''\n",
    "if len(str1) == len(str2):\n",
    "    if str1 == str2:\n",
    "        ls = str1\n",
    "    elif (str2[0]*len(str2) == str2) & (str2[0]*len(str1) == str1):\n",
    "            ls = str1[0]\n",
    "    else:\n",
    "        ls=''\n",
    "        \n",
    "elif len(str2) > len(str1):\n",
    "    str3 = str2\n",
    "    str2 = str1\n",
    "    str1 = str3\n",
    "    if len(str2) < len(str1):\n",
    "        if str1 == str2+str2:\n",
    "            ls = str2\n",
    "        elif True:\n",
    "            for i in range(len(str2),0,-2):\n",
    "                if str2[:i]*(len(str2)//i) == str2:\n",
    "                    if str2[:i]*(len(str1)//i) == str1:\n",
    "                        ls = str2[:i]\n",
    "                        print(ls)\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    continue\n",
    "        elif (str2[0]*len(str2) == str2) & (str2[0]*len(str1) == str1):\n",
    "            ls = str1[0]\n",
    "        else:\n",
    "            ls=''\n",
    "else:\n",
    "        if str1 == str2+str2:\n",
    "            ls = str2\n",
    "        elif True:\n",
    "            for i in range(len(str2),0,-1):\n",
    "                if str2[:i]*(len(str2)//i) == str2:\n",
    "                    if str2[:i]*(len(str1)//i) == str1:\n",
    "                        ls = str2[:i]\n",
    "        elif (str2[0]*len(str2) == str2) & (str2[0]*len(str1) == str1):\n",
    "            ls = str1[0]\n",
    "        else:\n",
    "            ls=''\n",
    "print(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af78b2a2-5c9b-4a17-993f-9772aa2ee0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
